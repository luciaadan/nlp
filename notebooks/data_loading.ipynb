{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b82b07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "16718e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'train.jsonl', 'test': 'test.jsonl'}\n",
    "temp_set = pd.read_json(\"hf://datasets/sh0416/ag_news/\" + splits[\"train\"], lines=True)\n",
    "test_set = pd.read_json(\"hf://datasets/sh0416/ag_news/\" + splits[\"test\"], lines=True)\n",
    "\n",
    "train_set, val_set = train_test_split(temp_set, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2810e14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_labels_text(set: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    x = set.drop(columns=[\"label\"])\n",
    "    y = set[\"label\"]\n",
    "\n",
    "    return x,y \n",
    "\n",
    "ag_train, y_train = separate_labels_text(train_set)\n",
    "ag_val, y_val = separate_labels_text(val_set)\n",
    "ag_test, y_test = separate_labels_text(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "85c58e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "X_train = tfidf.fit_transform(ag_train[\"title\"]+ag_train[\"description\"])\n",
    "X_val = tfidf.transform(ag_val[\"title\"]+ag_val[\"description\"])\n",
    "X_test = tfidf.transform(ag_test[\"title\"]+ag_test[\"description\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f4107542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 1821126 stored elements and shape (108000, 5000)>\n",
      "  Coords\tValues\n",
      "  (0, 2315)\t0.3682716628747734\n",
      "  (0, 63)\t0.14929878428808951\n",
      "  (0, 789)\t0.25609629646631094\n",
      "  (0, 2883)\t0.25938368292731045\n",
      "  (0, 608)\t0.18023286272425898\n",
      "  (0, 2288)\t0.14510910068144578\n",
      "  (0, 415)\t0.218375145919774\n",
      "  (0, 1525)\t0.1799257942863951\n",
      "  (0, 223)\t0.17386587457034536\n",
      "  (0, 534)\t0.1852029848013651\n",
      "  (0, 3971)\t0.15791067383751484\n",
      "  (0, 2755)\t0.4681631903347782\n",
      "  (0, 4986)\t0.12434476241419706\n",
      "  (0, 4765)\t0.2404714498033257\n",
      "  (0, 3982)\t0.14796078466543375\n",
      "  (0, 1069)\t0.19049214671034992\n",
      "  (0, 1520)\t0.14425331481369189\n",
      "  (0, 4870)\t0.1295129185251378\n",
      "  (0, 1795)\t0.19370024135402827\n",
      "  (0, 3011)\t0.1702530803678367\n",
      "  (0, 3438)\t0.17725905994123434\n",
      "  (1, 63)\t0.08649362511507508\n",
      "  (1, 1520)\t0.16714124220899954\n",
      "  (1, 250)\t0.44232163710409395\n",
      "  (1, 1514)\t0.23026227180773629\n",
      "  :\t:\n",
      "  (107998, 4037)\t0.2597332646494897\n",
      "  (107998, 4982)\t0.14753170202825136\n",
      "  (107998, 1644)\t0.17973968858857664\n",
      "  (107998, 3525)\t0.28035280356561176\n",
      "  (107998, 635)\t0.18941767657557723\n",
      "  (107998, 4240)\t0.2200595452552746\n",
      "  (107998, 2021)\t0.27383548379025174\n",
      "  (107998, 2051)\t0.2626258343802285\n",
      "  (107998, 2716)\t0.2494329526664729\n",
      "  (107998, 3200)\t0.4955278421470906\n",
      "  (107998, 2776)\t0.24263059052696614\n",
      "  (107998, 652)\t0.24892363762214076\n",
      "  (107999, 4145)\t0.39033850878010384\n",
      "  (107999, 2941)\t0.1849245499606892\n",
      "  (107999, 3214)\t0.15526017427812103\n",
      "  (107999, 2438)\t0.37255447791003765\n",
      "  (107999, 3684)\t0.1666741758904653\n",
      "  (107999, 4311)\t0.20101901704885083\n",
      "  (107999, 113)\t0.24218092137808592\n",
      "  (107999, 1233)\t0.2838858967728382\n",
      "  (107999, 1801)\t0.4183626873104532\n",
      "  (107999, 3704)\t0.21785141295454072\n",
      "  (107999, 1231)\t0.24583055341071988\n",
      "  (107999, 4855)\t0.26998364518272466\n",
      "  (107999, 4886)\t0.2954556913499429\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518f380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(param_grid, x_train, y_train, x_val, y_val):\n",
    "    best_model = None\n",
    "    best_macrof1 = 0\n",
    "    best_params = None\n",
    "\n",
    "    for c in param_grid[\"C\"]:\n",
    "        for l1_ratio in param_grid[\"l1_ratio\"]:\n",
    "            for solver in param_grid[\"solver\"]:\n",
    "                for max_iter in param_grid[\"max_iter\"]:\n",
    "                    if solver in [\"lbfgs\", \"newton-cg\", \"sag\"] and l1_ratio != 0:\n",
    "                        continue\n",
    "\n",
    "                    if 0 < l1_ratio < 1 and solver != \"saga\":\n",
    "                        continue\n",
    "\n",
    "                    logmodel = LogisticRegression(\n",
    "                        C=c,\n",
    "                        l1_ratio=l1_ratio,\n",
    "                        solver=solver,\n",
    "                        max_iter=max_iter,\n",
    "                        random_state=42,\n",
    "                    )\n",
    "\n",
    "                    logmodel.fit(x_train, y_train)\n",
    "\n",
    "                    y_pred = logmodel.predict(x_val)\n",
    "                    \n",
    "                    new_score = f1_score(y_val, y_pred, average=\"macro\")\n",
    "\n",
    "                    if new_score > best_macrof1:\n",
    "                        best_macrof1 = new_score\n",
    "                        best_model = logmodel\n",
    "                        best_params = {\n",
    "                            \"C\": c,\n",
    "                            \"l1_ratio\": l1_ratio,\n",
    "                            \"solver\": solver,\n",
    "                            \"max_iter\": max_iter,\n",
    "                        }\n",
    "\n",
    "    return best_model, best_macrof1, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d65f72b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      1\u001b[39m param_grid = {\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mC\u001b[39m\u001b[33m\"\u001b[39m: np.logspace(-\u001b[32m4\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m8\u001b[39m),\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33ml1_ratio\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[32m0\u001b[39m, \u001b[32m0.2\u001b[39m, \u001b[32m0.4\u001b[39m, \u001b[32m0.6\u001b[39m, \u001b[32m0.8\u001b[39m, \u001b[32m1\u001b[39m],\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msolver\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33mlbfgs\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mnewton-cg\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msag\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msaga\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmax_iter\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[32m50\u001b[39m, \u001b[32m100\u001b[39m, \u001b[32m500\u001b[39m, \u001b[32m1000\u001b[39m],\n\u001b[32m      6\u001b[39m }\n\u001b[32m      8\u001b[39m grid_search = GridSearchCV(logreg, param_grid, scoring=\u001b[33m\"\u001b[39m\u001b[33mf1_macro\u001b[39m\u001b[33m\"\u001b[39m, cv=\u001b[32m5\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/NLP/nlp/.venv/lib/python3.12/site-packages/sklearn/base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/NLP/nlp/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1053\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1047\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1048\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1049\u001b[39m     )\n\u001b[32m   1051\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1056\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1057\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/NLP/nlp/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1612\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1610\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1611\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1612\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/NLP/nlp/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:999\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    991\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    992\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    993\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    994\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    995\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    996\u001b[39m         )\n\u001b[32m    997\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m999\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1021\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1022\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/NLP/nlp/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:91\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     79\u001b[39m warning_filters = (\n\u001b[32m     80\u001b[39m     filters_func() \u001b[38;5;28;01mif\u001b[39;00m filters_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m warnings.filters\n\u001b[32m     81\u001b[39m )\n\u001b[32m     83\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     84\u001b[39m     (\n\u001b[32m     85\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     90\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/NLP/nlp/.venv/lib/python3.12/site-packages/joblib/parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/NLP/nlp/.venv/lib/python3.12/site-packages/joblib/parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/NLP/nlp/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:184\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    180\u001b[39m                 this_warning_filter_dict[special_key] = this_value.pattern\n\u001b[32m    182\u001b[39m         warnings.filterwarnings(**this_warning_filter_dict, append=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/NLP/nlp/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:833\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    831\u001b[39m         estimator.fit(X_train, **fit_params)\n\u001b[32m    832\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m         \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    836\u001b[39m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[32m    837\u001b[39m     fit_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/NLP/nlp/.venv/lib/python3.12/site-packages/sklearn/base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/NLP/nlp/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1262\u001b[39m, in \u001b[36mLogisticRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1258\u001b[39m \u001b[38;5;66;03m# TODO: enable multi-threading if benchmarks show a positive effect,\u001b[39;00m\n\u001b[32m   1259\u001b[39m \u001b[38;5;66;03m# see https://github.com/scikit-learn/scikit-learn/issues/32162\u001b[39;00m\n\u001b[32m   1260\u001b[39m n_threads = \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1262\u001b[39m coefs, _, n_iter = \u001b[43m_logistic_regression_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1263\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1264\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1265\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mCs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1267\u001b[39m \u001b[43m    \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1271\u001b[39m \u001b[43m    \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m=\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1272\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1275\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1276\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcoef\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1277\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1278\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1279\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1280\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1281\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1283\u001b[39m \u001b[38;5;28mself\u001b[39m.n_iter_ = np.asarray(n_iter, dtype=np.int32)\n\u001b[32m   1285\u001b[39m \u001b[38;5;28mself\u001b[39m.coef_ = coefs[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/NLP/nlp/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:416\u001b[39m, in \u001b[36m_logistic_regression_path\u001b[39m\u001b[34m(X, y, classes, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[39m\n\u001b[32m    414\u001b[39m     l2_reg_strength = \u001b[32m1.0\u001b[39m / (C * sw_sum)\n\u001b[32m    415\u001b[39m     args = (X, target, sample_weight, l2_reg_strength, n_threads)\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     w0, n_iter_i = \u001b[43m_newton_cg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_hess\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m=\u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m solver == \u001b[33m\"\u001b[39m\u001b[33mnewton-cholesky\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    427\u001b[39m     l2_reg_strength = \u001b[32m1.0\u001b[39m / (C * sw_sum)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/NLP/nlp/.venv/lib/python3.12/site-packages/sklearn/utils/optimize.py:294\u001b[39m, in \u001b[36m_newton_cg\u001b[39m\u001b[34m(grad_hess, func, grad, x0, args, tol, maxiter, maxinner, line_search, warn, verbose)\u001b[39m\n\u001b[32m    290\u001b[39m termcond = eta * maggrad\n\u001b[32m    292\u001b[39m \u001b[38;5;66;03m# Inner loop: solve the Newton update by conjugate gradient, to\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[38;5;66;03m# avoid inverting the Hessian\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m xsupi = \u001b[43m_cg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfhess_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaxinner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtermcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    296\u001b[39m alphak = \u001b[32m1.0\u001b[39m\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m line_search:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/NLP/nlp/.venv/lib/python3.12/site-packages/sklearn/utils/optimize.py:157\u001b[39m, in \u001b[36m_cg\u001b[39m\u001b[34m(fhess_p, fgrad, maxiter, tol, verbose)\u001b[39m\n\u001b[32m    151\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    152\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Inner CG solver iteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m stopped with\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    153\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m    sum(|residuals|) <= tol: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.sum(np.abs(ri))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m <= \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    154\u001b[39m         )\n\u001b[32m    155\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m Ap = \u001b[43mfhess_p\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpsupi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[38;5;66;03m# check curvature\u001b[39;00m\n\u001b[32m    159\u001b[39m curv = np.dot(psupi, Ap)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/NLP/nlp/.venv/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:810\u001b[39m, in \u001b[36mLinearModelLoss.gradient_hessian_product.<locals>.hessp\u001b[39m\u001b[34m(s)\u001b[39m\n\u001b[32m    808\u001b[39m     s_intercept = \u001b[32m0\u001b[39m\n\u001b[32m    809\u001b[39m tmp = X @ s.T + s_intercept  \u001b[38;5;66;03m# X_{im} * s_k_m\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m810\u001b[39m tmp += \u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[43mproba\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m[:, np.newaxis]  \u001b[38;5;66;03m# - sum_l ..\u001b[39;00m\n\u001b[32m    811\u001b[39m tmp *= proba  \u001b[38;5;66;03m# * p_i_k\u001b[39;00m\n\u001b[32m    812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/NLP/nlp/.venv/lib/python3.12/site-packages/numpy/_core/_methods.py:47\u001b[39m, in \u001b[36m_sum\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, initial, where)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_amin\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     44\u001b[39m           initial=_NoValue, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_minimum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sum\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     48\u001b[39m          initial=_NoValue, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_prod\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     52\u001b[39m           initial=_NoValue, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"C\": np.logspace(-4, 2, 8),\n",
    "    \"l1_ratio\": [0, 0.2, 0.4, 0.6, 0.8, 1],\n",
    "    \"solver\": [\"lbfgs\", \"newton-cg\", \"sag\", \"saga\"],\n",
    "    \"max_iter\": [50, 100, 500, 1000],\n",
    "}\n",
    "\n",
    "best_model, best_macrof1, best_params = grid_search(param_grid, X_train, y_train, X_val, y_val)\n",
    "\n",
    "print(best_model)\n",
    "print(best_macrof1)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da895b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(xticks_rotation='vertical')\n",
    "plt.title(\"Confusion Matrix: TF-IDF + Logistic Regression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c475cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_svm(param_grid, x_train, y_train, x_val, y_val):\n",
    "    best_model = None\n",
    "    best_macrof1 = 0\n",
    "    best_params = None\n",
    "\n",
    "    for c in param_grid[\"C\"]:\n",
    "        for penalty in param_grid[\"penalty\"]:\n",
    "            for loss in param_grid[\"loss\"]:\n",
    "                if penalty == \"l1\" and loss == \"hinge\":\n",
    "                    continue\n",
    "\n",
    "                svm = LinearSVC(\n",
    "                    C=c,\n",
    "                    penalty=penalty,\n",
    "                    loss=loss,\n",
    "                    random_state=42,\n",
    "                    multi_class=\"ovr\",\n",
    "                )\n",
    "\n",
    "                svm.fit(x_train, y_train)\n",
    "\n",
    "                y_pred = svm.predict(x_val)\n",
    "                \n",
    "                new_score = f1_score(y_val, y_pred, average=\"macro\")\n",
    "\n",
    "                if new_score > best_macrof1:\n",
    "                    best_macrof1 = new_score\n",
    "                    best_model = svm\n",
    "                    best_params = {\n",
    "                        \"C\": c,\n",
    "                        \"penalty\": penalty,\n",
    "                        \"loss\": loss,\n",
    "                    }\n",
    "\n",
    "    return best_model, best_macrof1, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d40ee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_svm = {\n",
    "    \"C\": np.logspace(-4, 2, 8),\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"loss\": [\"hinge\", \"squared_hinge\"]\n",
    "}\n",
    "\n",
    "best_model_svm, best_macrof1_svm, best_params_svm = grid_search_svm(\n",
    "    param_grid_svm, X_train, y_train, X_val, y_val\n",
    ")\n",
    "\n",
    "print(best_model_svm)\n",
    "print(best_macrof1_svm)\n",
    "print(best_params_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586408c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_svm = best_model_svm.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_test_svm))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_test_svm)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(xticks_rotation='vertical')\n",
    "plt.title(\"Confusion Matrix: TF-IDF + Linear SVM\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7effd17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AG News label mapping\n",
    "label_names = {1: \"World\", 2: \"Sports\", 3: \"Business\", 4: \"Sci/Tech\"}\n",
    "\n",
    "# --- Logistic Regression Error Analysis ---\n",
    "df_predictions_lr = pd.DataFrame({\n",
    "    'text': ag_test[\"title\"] + ag_test[\"description\"],\n",
    "    'true_label': y_test.map(label_names),\n",
    "    'pred_label': pd.Series(y_pred_test).map(label_names).values\n",
    "})\n",
    "\n",
    "errors_lr = df_predictions_lr[df_predictions_lr['true_label'] != df_predictions_lr['pred_label']]\n",
    "\n",
    "print(\"=== Logistic Regression ===\")\n",
    "print(f\"Total Errors: {len(errors_lr)}\")\n",
    "print(\"Displaying first 20 misclassifications:\")\n",
    "display(errors_lr.head(20))\n",
    "\n",
    "# --- LinearSVC Error Analysis ---\n",
    "df_predictions_svm = pd.DataFrame({\n",
    "    'text': ag_test[\"title\"] + ag_test[\"description\"],\n",
    "    'true_label': y_test.map(label_names),\n",
    "    'pred_label': pd.Series(y_pred_test_svm).map(label_names).values\n",
    "})\n",
    "\n",
    "errors_svm = df_predictions_svm[df_predictions_svm['true_label'] != df_predictions_svm['pred_label']]\n",
    "\n",
    "print(\"\\n=== LinearSVC ===\")\n",
    "print(f\"Total Errors: {len(errors_svm)}\")\n",
    "print(\"Displaying first 20 misclassifications:\")\n",
    "display(errors_svm.head(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
